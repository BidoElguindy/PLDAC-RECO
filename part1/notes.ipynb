{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70bd4066-d323-4f3a-87ea-e1d0dce3e85f",
   "metadata": {},
   "source": [
    "# Conclusion de la 1er semaine\n",
    "\n",
    "## Les donnés\n",
    "\n",
    "- We found many inconsistenties in the data (the nombre of non reviewed games between datasets\n",
    "- we found 2 spam reviews\n",
    "- No correlation between the number of reviews and rating\n",
    "- Also no correlation between length of the review with the rating given\n",
    "- There is a notable skew in the ratings distribution, with most ratings clustering around 7-8\n",
    "- The data needs more cleaning\n",
    "\n",
    "## Diffucltés\n",
    "\n",
    "- The number of review are really low in comparison to the number of user*games without any cleaning we have 196814241 missing values with a fill rate of 0.08% which caused us big computional problems which meant that we spent a long time trying to fill the nun values.\n",
    "- So we decided to take a very small portions of our data to be able to test knn. (games with more then 120 ratings and users who rated these games)\n",
    "- With a fill rate so low we tried three different techniques to fill the values, first we tried to do a normal distrubition on each person while taking into consideration which category the game was in and if the person has other ratings in the same categories but this method appeared to be heavy on runtime and diffuclt to well implement as when tested on a small test dataset we found that due to the nature of how people rate (so most ratings are around 7) the disturbution was very centered around 7 and didnt capture well low ratings.\n",
    "- So we decided to try a mean method where we took the mean of both the mean of the column(game) and the mean of lines (user), this showed  way better results but we also want to try with Singular value decomposition (svd) so we can see if we can use the patterns in the data to create better results.\n",
    "- The statistics of svd fitted more with what we are trying to do so we choose it\n",
    "\n",
    "## KNN\n",
    "\n",
    "- with different folds, different number of neighbor, with different error metrics we discoverd multiple things:\n",
    "    - First of the  manhatan distance had the worst results out of the 3, both euclidiene and cosine had very similar and better errors\n",
    "    - while the error seems low, while looking at the graph and the std error we can see a big problem when it predicts wrong, it predicts them very wrong( predicting ratings that are less then 2 as high as 8 !!!!\n",
    "    - Between the number of neighbor their wasnt any big difference in the results and also with different fold (although to be noted the 3rd fold was the best and the 2nd the worst).\n",
    "    - The model seem to overly optimistic with its prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c678d17-6166-44ef-acf1-28cc3b6447e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c023a6a3",
   "metadata": {},
   "source": [
    "Let's compare both train-test split approaches for your recommendation system:\n",
    "\n",
    "Custom train_test_split:\n",
    "Pros:\n",
    "\n",
    "Preserves user and item representation by ensuring no user or game loses too many ratings (controlled by max_user_loss and max_game_loss)\n",
    "More realistic for recommendation systems where you need enough data per user/item\n",
    "Prevents cold-start problems in your test set\n",
    "Better controls distribution across users and items\n",
    "Cons:\n",
    "\n",
    "More complex implementation\n",
    "Might not be perfectly random (prioritizes maintaining user/item representation)\n",
    "Surprise train_test_split:\n",
    "Pros:\n",
    "\n",
    "Simple, purely random split\n",
    "Built into the Surprise library\n",
    "Ensures test_size percentage is exact\n",
    "Cons:\n",
    "\n",
    "No control over how many ratings each user/item loses\n",
    "May create \"cold-start\" situations in your test set\n",
    "Could leave some users or items with no training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc3b7d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
